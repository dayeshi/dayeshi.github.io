{"pages":[],"posts":[{"title":"Python+selenium实现疫情期间自动健康报告打卡","text":"😅需求因疫情形势严峻，我校2月11日起，要求学生每天上报健康状态，打卡时间为每天13点至20点。具体操作是进入指定网址，登录校园统一认证系统，填入一大堆信息，提交。第二次及以后填报时会自动拉取前一次的填报内容，所以只需要点提交即可。 既然每天都要做这样机械的事，何不让Python帮我做？ 😋分析分析了填报过程，填报系统设计得非常臃肿，加载缓慢。提交过程post的表单数据条数太多太杂，如果用requests库不好构建form。于是想尝试一下之前没用过的selenium+Chrome浏览器驱动。 😉实现123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144# -*- coding: utf-8 -*-import datetimeimport timeimport osimport smtplibfrom email.mime.text import MIMETextfrom email.utils import formataddrfrom email.mime.image import MIMEImagefrom email.mime.multipart import MIMEMultipartfrom email.header import Headerfrom selenium import webdriverfrom selenium.webdriver.common.by import Byfrom selenium.webdriver.support.ui import WebDriverWaitfrom selenium.webdriver.support import expected_conditions as EC# 定义日志函数def write_info(str): pyfile = f'{os.path.basename(__file__)}' with open('log.txt', 'a+') as f: f.write('\\n' + '[' + pyfile + '] ' + '[' + f'{datetime.datetime.now():%Y-%m-%d %H:%M:%S}' + '] ' + str) f.close()# 定义发送邮件函数def send_mail(copyfrom, title, account, img_name, status): my_sender = 'xxxxx@163.com' # 发件人邮箱 my_pass = 'abcdefghijk' # 发件人邮箱客户端授权码 my_user = account # 收件人邮箱 def mail(): ret = True try: msg = MIMEMultipart('related') msg['From'] = formataddr([copyfrom, my_sender]) msg['To'] = formataddr([account, my_user]) msg['Cc'] = formataddr([copyfrom, my_sender]) subject = title msg['Subject'] = Header(subject, 'utf-8') msgAlternative = MIMEMultipart('alternative') msg.attach(msgAlternative) # 邮件正文以HTML形式显示，其中包含图片 html = f&quot;&quot;&quot; &lt;div&gt; &lt;p&gt;今日报告状态：{status}&lt;/p&gt; &lt;p&gt;&lt;img src=&quot;cid:image1&quot;&gt;&lt;/p&gt; &lt;/div&gt; &quot;&quot;&quot; msgAlternative.attach(MIMEText(html, 'html', 'utf-8')) # 指定图片为当前目录 fp = open(f'{img_name}', 'rb') msgImage = MIMEImage(fp.read()) fp.close() # 定义图片ID，在HTML文本中引用 msgImage.add_header('Content-ID', '&lt;image1&gt;') msg.attach(msgImage) server = smtplib.SMTP_SSL(&quot;smtp.163.com&quot;, 465) server.login(my_sender, my_pass) server.sendmail(my_sender, [my_user], msg.as_string()) server.quit() except Exception: ret = False return ret ret = mail() if ret: write_info(f'邮件发送成功至{account}') else: write_info(f'邮件发送至{account}失败')def main(xuehao, mima, youxiang): global number # 设置number为全局变量 mobileEmulation = {'deviceName': 'iPhone 4'} # 指定设备 options = webdriver.ChromeOptions() options.add_argument(&quot;--headless&quot;) options.add_argument('--disable-gpu') options.add_argument('--no-sandbox') options.add_experimental_option('mobileEmulation', mobileEmulation) driver = webdriver.Chrome(executable_path=r&quot;./chromedriver&quot;, options=options) driver.implicitly_wait(120) # 隐性等待120秒，即可以等待网页响应时间不能超过120秒 driver.get(&quot;http://ehall.sicnu.edu.cn/qljfwapp/sys/lwReportEpidemicUndergraduate/*default/index.do&quot;) write_info('打开网页，准备登录') username = driver.find_element_by_id(&quot;mobileUsername&quot;) password = driver.find_element_by_id(&quot;mobilePassword&quot;) username.send_keys(xuehao) time.sleep(1) password.send_keys(mima) time.sleep(1) login_button = driver.find_element_by_id('load') login_button.click() write_info('登录成功') try: write_info('点击新增，最长等待60秒') WebDriverWait(driver, 60).until( EC.presence_of_element_located((By.XPATH, '/html/body/div[1]/div/button')) ) element = driver.find_element_by_xpath(&quot;/html/body/div[1]/div/button&quot;) driver.execute_script(&quot;arguments[0].click();&quot;, element) WebDriverWait(driver, 60).until( EC.text_to_be_present_in_element((By.XPATH, '/html/body/div[1]/div/div/div[2]/div/div[1]/div/div[2]/div[' '12]/div/a/div[2]/div[2]/span'), 'XXX校区') ) js = &quot;var ele = document.getElementById('app');ele.scrollTop = ele.scrollHeight;&quot; driver.execute_script(js) write_info('滑到页面底部') tijiao = driver.find_element_by_xpath('//*[@id=&quot;app&quot;]/div/div/div[3]/button') tijiao.click() queding = driver.find_element_by_xpath('/html/body/div[3]/div/div[3]/button[2]') queding.click() time.sleep(1) driver.save_screenshot(f'{datetime.datetime.now():%Y-%m-%d}-{xuehao}.png') # 成功截屏 write_info(f'填报成功：{datetime.datetime.now():%Y-%m-%d}-{xuehao}.png') send_mail('XX疫情报告助手', '今日填报情况', youxiang, f'{datetime.datetime.now():%Y-%m-%d}-{xuehao}.png', '成功') number = 5 except: driver.save_screenshot(f'{datetime.datetime.now():%Y-%m-%d}-{xuehao}.png') # 失败截屏 write_info(f'填报失败：{datetime.datetime.now():%Y-%m-%d}-{xuehao}.png') driver.quit() # 第五次失败时，发送错误信息给用户 if number &gt; 3: send_mail('XX疫情报告助手', '今日填报情况', youxiang, f'{datetime.datetime.now():%Y-%m-%d}-{xuehao}.png', '失败') number += 1 time.sleep(60)if __name__ == &quot;__main__&quot;: # 可多用户 people_list = [ ['账号1', &quot;密码&quot;, '邮箱'], ['账号2', &quot;密码&quot;, '邮箱'], ] number = 0 # 全局变量 for p in people_list: try: # 若失败，重新尝试5次 while number &lt; 5: main(p[0], p[1], p[2]) number = 0 except: write_info(f'打卡失败：{p[0]}') 😁运行下载Chrome浏览器驱动，放到py文件相同目录下。放在阿里云上，用crontab每天定时执行。 1crontab -e 在其中新增一行，每天13点04分运行： 104 13 * * * cd /root/xxxxx_report &amp;&amp; /root/anaconda3/bin/python xxxxx.py ps:之所以不13点准时运行，是因为学校那破系统时间不是快2分钟就是慢两分钟，原因不明。 😙效果配合学校的edu邮箱体验更好。 😮注意163邮箱有个坑，当发送含有图片的邮件时，可能会被视为垃圾邮件，导致报错，解决方法是发送时给自己抄送一份。","link":"/2020/03/11/6nXxal4Te/"},{"title":"加密DNS，为你的设备开启DoH或DoT","text":"前言最近看到一条热搜，联通用户可以自己查询上网记录，可以精确到什么时间访问了哪些网站，可能比你的浏览器历史记录还详细。移动和电信好像没提供类似的功能，但这也意味着运营商可以详尽记录你的上网痕迹。这不禁让我感到有点后怕，于是查了查有没有可以提升上网隐私安全性的技术，发现DoH和DoT可以帮我们给网络行为加层保护，避免请求被窃取和篡改。 DNS和它的缺点我们访问一个网站，通常是在浏览器输入域名然后回车，就能访问到相应的内容。在这个过程中DNS就起到了把域名转换为相应IP地址的作用。 然而浏览器通过UDP协议以明文的方式请求，这个请求的过程是透明的，你访问的任何网站都可以被可以监视传输过程的人偷窥，例如互联网服务提供商（移动、电信、联通），网络中的用户。有时候攻击者甚至可以劫持DNS，从而导致你访问不了相应的网站。 这就像你写了一封信，没有信封，然后通过邮局寄出去，在你的信传递过程中的任何工作人员都可以看到你写的信的内容。 把信装到信封里：加密DNSDoH: DNS over HTTPSDoH是基于HTTPS协议发送的，默认端口是443，因此它的流量特征和我们正常访问HTTPS网站是一样的，因此有很强的迷惑性。互联网服务提供商或其它中间网络设备无法解密或获知请求的实际内容，更不能篡改已经加密的HTTPS通信，故其能够有效保护用户的安全及隐私。 DoT: DNS over TLSDoT是基于TCP协议发送的，并且加了TLS安全协议，默认端口是853。可见DoT具有专用端口，因此即使请求和响应本身都已加密，具有网络可见性的任何人都可以看到来回的DoT流量。 DoH VS DoTDoH和DoT哪个好？我个人认为端口是主要区别，DoH的443端口可以具有隐蔽性，相对好一点。不过对于普通用户来说，能实现加密传输就行，因此两个都可以，不分伯仲。 哪些公共DNS支持DoH/DoT？国内 公共DNS提供商 官方网址 腾讯DNSPod 链接 阿里公共DNS 链接 国外 公共DNS提供商 官方网址 CloudflareDNS 链接 Google公共DNS 链接 选哪个？如果没特殊需求，建议选国内的，相对快很多。然后打开自己电脑的cmd，ping一下哪家的平均时间短，就选短的，各地不一样，我这里阿里的比较好。这里附上一份全球知名DNS提供商名单：链接 哪些设备支持DoH/DoT？有些设备可以通过安装软件支持，这里介绍比较简单的官方方法，默认以阿里的DoH/DoT为例。 iOS/iPad OS 14.0及以上iPhone和iPad最新系统已经支持，只是需要安装描述文件才能开启，以iPhone为例，Safari浏览器打开此链接：链接，备用链接 点击允许后，去设置-已下载的描述文件-安装-（可能提示警告）安装-完成。然后去设置-通用-VPN与网络-DNS，可以看到刚安装的文件，至此已经设置完成。 更多配置文件见链接 安卓 9 及以上原生安卓：设置-网络和互联网-高级-私人DNS(Private DNS)，手动输入DoT(注意这里只支持DoT)，例如阿里的dns.alidns.com 小米MIUI：设置-连接与共享-私人DNS，手动输入DoT(注意这里只支持DoT)，例如阿里的dns.alidns.com 华为EMUI：设置-无线和网络-加密DNS，手动输入DoT(注意这里只支持DoT)，例如阿里的dns.alidns.com 其他安卓机型类似，如果没有，可下载第三方软件实现。 Win10截至目前，正式版还没支持，但是可通过加入Windows测试，改注册表，第三方软件等方式开启DoH/DoT。但是最新版Chrome浏览器和Firefox浏览器已经支持，下面介绍如何设置。 Chrome浏览器设置-隐私设置和安全性-安全-高级-使用安全DNS-自定义，输入https://dns.alidns.com/dns-query? Firefox浏览器设置-常规-网络设置-设置-启用基于HTTPS的DNS-自定义，输入https://dns.alidns.com/dns-query? 验证是否成功网页访问网易的检测链接，看看开启DoH/DoT前后，DNS地址信息是否明显变化，例如可以去查查IP的归属。","link":"/2021/01/28/8qrxgf1VY/"},{"title":"博客从GitHub迁移至腾讯云","text":"GitHub真的真的访问太慢了，加上套的腾讯云的CDN仍然慢哭了，所以转身投向腾讯云的怀抱。但是腾讯云还有几个月快到期了，本来想着把博客迁移至阿里云的，毕竟学生机器白嫖的6个月不能浪费😝可惜没想到国内备案服务商之间竟然不能通用，把在腾讯云买的域名解析到阿里云服务器，提示备案🤦‍♀🤦‍♂去看了下能不能把腾讯云备案转过去，网上搜了一圈，并没有这种操作，还得重新备案🌚🌝而且审核时间还要几天🌚🌝那只有先将就用我的腾讯云了，但是以后估计还得迁移，毕竟续费一个月100多🙉🙉🙉。 🍀配置NginxCentOS直接安装 1yum install nginx -y 启动nginx 1nginx 输入服务器IP，查看是否能够访问，能访问进入下一步，不能访问查看80和443端口是否开放，没有就去安全组中开放这两个端口 在/data/www这个路径下存入博客相关文件，没有的话自己创建文件夹，Gridea现支持SFTP，配置如下⬇️找到Nginx配置文件夹，我的是在/etc/nginx，然后申请腾讯云的免费SSL证书，下载解压出来，把Nginx文件夹中的两个文件XXXXX.crt和XXXXX.key放到服务器的/etc/nginx文件夹下，然后在/etc/nginx/con.d中新建立一个文件XXXXX.conf,XXXXX可以你自己命名无所谓。用vim编辑这个文件⬇️ 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748server { #侦听443端口，这个是ssl访问端口 listen 443 ssl; #定义使用 访问域名 server_name www.XXXXX.cn XXXXX.cn;#这里修改成你自己的域名，该域名应解析至此服务器IP #定义服务器的默认网站根目录位置 root /data/www;#注意这里就是上面存放博客相关文件的路径 #设定本虚拟主机的访问日志 # 这些都是腾讯云推荐的配置，直接拿来用就行了，只是修改证书的路径，注意这些路径是相对于/etc/nginx/nginx.conf文件位置 ssl_certificate 1_www.XXXXX.cn_bundle.crt; ssl_certificate_key 2_www.XXXXX.cn.key; ssl_session_timeout 5m; ssl_protocols TLSv1 TLSv1.1 TLSv1.2; #按照这个协议配置 ssl_ciphers ECDHE-RSA-AES128-GCM-SHA256:HIGH:!aNULL:!MD5:!RC4:!DHE;#按照这个套件配置 ssl_prefer_server_ciphers on; #默认请求 location / { root /data/www; #定义首页索引文件的名称 index index.html; } #静态文件，nginx自己处理 location ~ ^/(images|javascript|js|css|flash|media|static)/ { #过期30天，静态文件不怎么更新，过期可以设大一点， #如果频繁更新，则可以设置得小一点。 expires 30d; } #禁止访问 .htxxx 文件 # location ~ /.ht { # deny all; #}}server{ # 80端口是http正常访问的接口 listen 80; server_name www.XXXXX.cn XXXXX.cn; # 在这里，我做了https全加密处理，在访问http的时候自动跳转到https rewrite ^(.*)$ https://$host$1 permanent;} 填入上面这些，注意里面有XXXXX都要改成你自己的。输入重启命令 1nginx -s reload 理论上浏览器输入域名就就可以访问了。 🌳将不带www域名重定向到wwwnginx 配置文件中新增如下： 12345server { listen 443 ssl; server_name imokey.cn; return 301 https://www.imokey.cn$request_uri;} 参考：壹言beyond__devil","link":"/2020/03/22/GypkaHl2Q/"},{"title":"“ABC News”新闻文本分析","text":"📒需求最近写毕业论文，需要研究分析“ABC News”对于新疆的报道内容，搜了一下，从2008年至今大约有300篇报道，于是想着通过Python爬下来再慢慢分析，包括自动翻译，关键词提取，词频计算，情感分析，主观性分析。 📕分析首先通过ABC News内置的搜索栏搜索，发现搜索结果直接返回Json格式的数据，这些数据可直接获知每篇新闻的url，标题，分类，来源，发布日期等。翻下一页，观察url变化为10，也就是每页返回10个结果，后面可直接据此构造url。 📗实现内容爬取需要用到的库 123456789101112131415from newspaper import Articlefrom textblob import TextBlobimport requestsimport jsonimport reimport osimport requestsimport pymongoimport timeimport datetimeimport smtplibfrom lxml import etreeimport jiebafrom nltk import FreqDistfrom monkeylearn import MonkeyLearn 根据分析，构造搜索的url，通过得到的Json提取每篇新闻的url和新闻标题。 1234567891011121314151617181920212223242526272829303132333435# 填入数据库信息database = &quot;ABC_News&quot;collection = &quot;ABCNews_title_url_deduplicate_by_url&quot;# 定义数据库插入函数def pymongo_insert(e): myclient = pymongo.MongoClient(&quot;mongodb://root:abcde123@xxxxx.com:27017/&quot;) mydb = myclient[database] mycol = mydb[collection] each_title = r['item'][e]['title'] each_url = r['item'][e]['link'] insert_results = {'success': 0, 'failure': 0} mydict = {&quot;01_title&quot;: each_title, &quot;02_url&quot;: each_url} print(mydict) if mycol.find_one({&quot;02_url&quot;: each_url}) is None: result = mycol.insert_one(mydict) insert_results['success'] = insert_results['success'] + 1 else: insert_results['failure'] = insert_results['failure'] + 1 print( f'{datetime.datetime.now():%Y-%m-%d %H:%M:%S} 插入成功{insert_results[&quot;success&quot;]}条,{insert_results[&quot;failure&quot;]}条数据已存在')# 爬取并遍历Json数据for i in range(1, 32): n = i - 1 url_1 = 'https://abcnews.go.com/meta/api/search?q=xinjiang&amp;limit=10&amp;sort=date-asc&amp;type=&amp;section=&amp;totalrecords' \\ headers = { &quot;User-Agent&quot;: &quot;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) &quot; &quot;Chrome/72.0.3626.96 Safari/537.36&quot;, } response = requests.get(url_1, headers=headers) r = response.json() last = len(r['item']) for e in range(0, last): pymongo_insert(e) 爬取结果：添加更多属性，日期、时间、星期、版权、分类、类型： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253# 分解出日期def convert_to_date(date): YMD = re.search(r'\\d+\\s\\S+\\s\\d+', date).group() week = re.search(r'\\w*', date).group() HMS = re.search(r'([01]?\\d|2[0-3]):[0-5]?\\d:[0-5]?\\d', date).group() sp = YMD.split() ori = {'Jan': '01', 'Feb': '02', 'Mar': '03', 'Apr': '04', 'May': '05', 'Jun': '06', 'Jul': '07', 'Aug': '08', 'Sep': '09', 'Oct': '10', 'Nov': '11', 'Dec': '12'} for i in ori: if sp[1] == i: sp[1] = ori[i] year = sp[2] month = sp[1] day = sp[0] return year, month, day, week, HMSheaders = { &quot;User-Agent&quot;: &quot;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) &quot; &quot;Chrome/72.0.3626.96 Safari/537.36&quot;,}myclient = pymongo.MongoClient(&quot;mongodb://root:abcde123@xxxxx.com:27017/&quot;)mydb = myclient[database]mycol = mydb[collection]# 添加日期、时间、星期、版权、分类、类型↓for i in range(1, 31): n = i - 1 url_1 = 'https://abcnews.go.com/meta/api/search?q=xinjiang&amp;limit=10&amp;sort=date-asc&amp;type=&amp;section=&amp;totalrecords' \\ '=true&amp;offset=' + str(n * 10) print(url_1) response = requests.get(url_1, headers=headers) r = response.json() last = len(r['item']) for e in range(0, last): each_url = r['item'][e]['link'] each_date = r['item'][e]['pubDate'] each_dcRights = r['item'][e]['dcRights'] each_category = r['item'][e]['category']['text'] each_dcType = r['item'][e]['dcType'] dcType = &quot;/&quot;.join(each_dcType) year, month, day, week, HMS = convert_to_date(each_date) condition = {'02_url': each_url} # 以每篇文章的url作为匹配依据 ABC = mycol.find_one(condition) ABC['03_year'] = year ABC['04_month'] = month ABC['05_day'] = day ABC['06_week'] = week ABC['07_HMS'] = HMS ABC['03_dcRights'] = each_dcRights ABC['03_category'] = each_category ABC['03_dcType'] = dcType result = mycol.update_one(condition, {'$set': ABC}) 完成效果：获取新闻正文，这里使用newspaper自动提取正文。 123456789101112131415161718# 使用newspaper获取新闻正文def get_text(each_url): try: article = Article(each_url) article.download() article.parse() return article.text except: lost_url_list.append(each_url) # 如果获取失败，把url添加到失败列表 return ''for x in mycol.find(): # 添加新闻正文内容↓ article = get_text(x['02_url']) condition = {'02_url': x['02_url']} ABC = mycol.find_one(condition) ABC['08_article_contents'] = article result = mycol.update_one(condition, {'$set': ABC}) 实现效果： 自动翻译这里使用的是TextBlob带的翻译方法，此操作必须在特殊网络下完成。它貌似调用的非官方谷歌翻译API，现已弃用该方法。 TextBlob.translate() and TextBlob.detect_language are deprecated. Use the official Google Translate API instead (#215). 新闻标题的翻译： 123456789101112# 自动翻译标题↓results = mycol.find({&quot;01_title_unreliable_translation&quot;: {&quot;$exists&quot;: False}})for r in results: if r['01_title'] != '': condition = {'02_url': r['02_url']} ABC = mycol.find_one(condition) translation = TextBlob(r['01_title']) r = translation.translate(from_lang=&quot;en&quot;, to='zh-CN') ABC['01_title_unreliable_translation'] = str(r) result = mycol.update_one(condition, {'$set': ABC}) else: print('The article is empty: ' + r['02_url']) 实现效果：新闻正文的翻译： 123456789101112# 自动翻译正文↓results = mycol.find({&quot;08_article_contents_unreliable_translation&quot;: {&quot;$exists&quot;: False}})for r in results: if r['08_article_contents'] != '': condition = {'02_url': r['02_url']} ABC = mycol.find_one(condition) translation = TextBlob(r['08_article_contents']) r = translation.translate(from_lang=&quot;en&quot;, to='zh-CN') ABC['08_article_contents_unreliable_translation'] = str(r) result = mycol.update_one(condition, {'$set': ABC}) else: print('The article is empty: ' + r['02_url']) 实现效果： 文本分析从新闻正文中提取关键词，计算词频。 12345678910111213141516171819202122232425262728293031323334# 获取词频def get_frequency(contents): contents = contents.lower() # 小写处理 contents = strip_punctuation(contents) res = contents.split() for i in dic: while i in res: res.remove(i) fdist1 = FreqDist(res) # 生成词频的字典，格式（“词1”：数量，“词2”：数量...） f = zip(fdist1.keys(), fdist1.values()) # 将字典压缩成list[('词1'，num1),('词2',num2),...] sortf = list(sorted(f, key=lambda s: s[1], reverse=True)) # f按照num排序 return sortf# 添加关键词词频↓for x in mycol.find(): words_frequency = get_frequency(x['08_article_contents']) if len(words_frequency) &gt; 9: # 过滤关键词个数小于10的文章 condition = {'02_url': x['02_url']} ABC = mycol.find_one(condition) n = 8 for i in range(10): b = i + 1 a = b + n if a &lt; 10: a = '0' + str(a) else: a = str(a) ABC[a + '_keyword_' + str(b)] = words_frequency[i][0] ABC[a + '_keyword_freq_' + str(b)] = words_frequency[i][1] result = mycol.update_one(condition, {'$set': ABC}) else: print('less than 10 keywords') for i in range(len(words_frequency)): print(words_frequency[i]) 实现效果：使用textblob.sentiments模块对新闻正文进行情感分析。textblob.sentiments包含两种情感分析实现方式，一种是PatternAnalyzer（默认），另一种是基于电影评论语料库训练出的 NaiveBayesAnalyzer。 利用textblob.classifiers模块可创建自定义情感分类器，详见这里。 1234567891011# TextBlob正面负面情感分析、主观客观性分析（正文）for x in mycol.find(): if x['08_article_contents'] != '': test = TextBlob(x['08_article_contents']) condition = {'02_url': x['02_url']} ABC = mycol.find_one(condition) ABC['20_polarity'] = test.sentiment.polarity ABC['21_subjectivity'] = test.sentiment.subjectivity result = mycol.update_one(condition, {'$set': ABC}) else: print('The article is empty: ' + x['02_url']) 实现效果：polarity极性：在 [-1,1]范围内的浮点数，其中1表示肯定陈述，-1表示否定陈述。subjectivity主观性：是指个人的意见和感受如何影响某人的判断力。主观性表示为浮点值，其范围为[0,1]。 使用MonkeyLearn的情感分析API对新闻正文进行分析，以作为参照。 123456789101112131415# MonkeyLearn情感分析↓for x in mycol.find(): ml = MonkeyLearn('34088daed813186e7a00xxxxxxxxxxxxxxxxx') data = [x['08_article_contents']] model_id = 'cl_pi3C7JiL' result = ml.classifiers.classify(model_id, data) if not result.body[0]['error']: condition = {'02_url': x['02_url']} ABC = mycol.find_one(condition) ABC['19_Sentiment'] = result.body[0]['classifications'][0]['tag_name'] ABC['19_Sentiment_Confidence'] = result.body[0]['classifications'][0]['confidence'] result = mycol.update_one(condition, {'$set': ABC}) else: print('error: '+x['02_url']) pass 实现效果： 📘总结TextBlob实际上是基于NLTK和pattern，但它让自然语言处理（NLP）更简单，更适合NLP入门使用。 TextBlob功能是比较丰富的：名词短语提取，词性标记，情感分析，朴素贝叶斯和决策树分类器，标记化（将文本分为单词和句子），单词和短语的频率，语法解析（Parsing），n元语法（n-grams），单词变形（复数和单数）和词形还原，拼写校正，通过扩展添加新模块或语言，WordNet集成。 📙参考TextBlob: Simplified Text ProcessingExploratory Data Analysis for Natural Language Processing.","link":"/2020/04/27/1zOqkL28j/"},{"title":"Padavan路由器设置frp内网穿透实现外网访问路由器管理页面+外网远程访问内网下的Windows桌面","text":"前段时间把小米路由器青春版刷了padavan固件，主要用来挂ss，其实这个系统很强大。但是原来可以用小米路由器APP远程管理，刷机之后就不行了，于是捣鼓了一下frp，成功实现外网访问路由器管理界面，另外实现了windows桌面的远程访问。 1、需要准备的东西 Linux VPS，推荐购买Vultr的，按小时计费（我的是腾讯云学生机，Linux系统环境是Ubuntu Server 16.04.1 LTS 64位） 刷了Padavan固件的路由器（我的是小米路由器青春版R1CL,padavan固件版本3.4.3.9-099_8-10-07） 2、配置服务端(frps.ini) 下面所有操作在服务器上完成 用putty连接服务器 root用户下操作 2.1、输入命令查看自己VPS的架构1arch 2.2、下载对应版本的压缩包解压123#如果输出×86_64那么就说明架构是arm64，即需要下载带linux_amd64的那个压缩包,目前最新的版本是v0.21.0wget https://github.com/fatedier/frp/releases/download/v0.21.0/frp_0.21.0_linux_amd64.tar.gz 如果输出的是其他的，就需要在这里找 linux 的对应架构的压缩包，复制下载地址，替换wegt后面的地址。 12345678#解压压缩包tar -xzvf frp_0.21.0_linux_amd64.tar.gz#将解压出来的文件夹名改成frp，方便后面操作mv frp_0.21.0_linux_amd64 frp#打开文件夹frpcd frp 2.3、修改配置文件frps.ini 12#用vim修改frps.inivim frps.ini 在frps.ini文件中写入如下内容 example.com替换成自己的域名 1234567891011121314#（必须）[common]#frp服务端端口（必须）bind_port = 7000#frp服务端密码（建议必须）token = 12345678#frp穿透访问内网中的http网站需要的端口（建议必须）vhost_http_port = 10080#frp穿透访问内网中的https网站需要的端口（建议必须）vhost_https_port = 10443 下面的可根据自己需要选填 123456#可视化仪表盘端口（非必须）dashboard_port = 7500#访问可视化仪表盘的用户名密码，可自行修改（非必须）dashboard_user = admindashboard_pwd = admin ↑仪表盘如上，访问地址为你的 VPS的公网ip:端口号dashboard_port ，如45.63.1.211:7500 12#设置自己的域名（非必须）subdomain_host = example.com 假设此项设置为 :example.com，后面的客户端配置(padavan路由器配置） web时将 subdomain设置为 router，然后你将router.example.com解析到服务端后，可以使用router.example.com:10080来访问路由器管理页面。 2.4、让服务端持续运行输入下面命令运行服务端 1./frps -c frps.ini 如果没有报错，那服务端运行正常。 但是现在服务端的设置还没完成，现在frps只是在前台运行，一旦关闭putty，frps就会关闭。 由于VPS一般是不关机的，所以只需要让frps持续在后台运行就行了，输入下面这条命令即可让frps后台运行。 1nohup /root/frp/frps -c /root/frp/frps.ini &amp; 3、配置padavan路由器客户端（frpc.ini）3.1、实现外网访问路由器管理页面 padavan的WiFi下打开192.168.123.1 扩展功能-花生壳内网版-frp-启用frp内网穿透和frpc客户端 然后点frp_script配置，这个里面已经预先写好了脚本，只需要我们修改”客户端配置”下的[common]和[web] 我的配置如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950#!/bin/shexport PATH='/etc/storage/bin:/tmp/script:/etc/storage/script:/opt/usr/sbin:/opt/usr/bin:/opt/sbin:/opt/bin:/usr/local/sbin:/usr/sbin:/usr/bin:/sbin:/bin'export LD_LIBRARY_PATH=/lib:/opt/libkillall frpc frpsmkdir -p /tmp/frp#启动frp功能后会运行以下脚本#使用方法请查看论坛教程地址: http://www.right.com.cn/forum/thread-191839-1-1.html#frp项目地址教程: https://github.com/fatedier/frp/blob/master/README_zh.md#请自行修改 auth_token 用于对客户端连接进行身份验证# IP查询： http://119.29.29.29/d?dn=github.com#客户端配置：cat &gt; &quot;/tmp/frp/myfrpc.ini&quot; &lt;&lt;-\\EOF[common]server_addr = 你的VPS的公网IPserver_port = 上面服务端frps.ini的bind_porttoken = 上面服务端frps.ini的token[web]type = httplocal_ip = 127.0.0.1local_port = 80use_encryption = trueuse_compression = true#路由器管理页面用户名和密码，自行设置，此处#设置的与路由器本身的登录名和密码不同http_user = admin（路由器管理页面的用户名）http_pwd = 12345678（路由器管理页面的密码）remote_port = 6000subdomain = router#假设此项设置为 :router，前面的服务端配置frps.ini时#将subdomain_host设置为example.com，然后你将#router.example.com解析到服务端后，可以使用router.example.com:10080#来访问路由器管理页面。EOF#启动：frpc_enable=`nvram get frpc_enable`frpc_enable=${frpc_enable:-&quot;0&quot;}frps_enable=`nvram get frps_enable`frps_enable=${frps_enable:-&quot;0&quot;}if [ &quot;$frpc_enable&quot; = &quot;1&quot; ] ; then frpc -c /tmp/frp/myfrpc.ini &amp;fiif [ &quot;$frps_enable&quot; = &quot;1&quot; ] ; then frps -c /tmp/frp/myfrps.ini &amp;fi [common]和[web]根据我的描述填写，其他的不用修改。点击最下面应用本页面设置。 这是我的padavan的运行日志，[web] start proxy success就说明内网穿透成功啦~ 外网情况下浏览器输入 你的公网ip:10080 或 r.example.com:10080即可访问路由器管理页面啦~ 这是我外网访问成功的界面 如果不行，检查你的防火墙设置和端口占用情况，分析服务端和客户端的运行日志。 3.2、实现外网远程访问内网下的Windows桌面先说一下我在这上面踩的坑，Windows 家庭版中的远程桌面被微软阉割了，所以如果被访问的主机装的这个版本是不能被远程控制的，但是道高一尺魔高一丈，解决方案在这。 123456[rdpqiang]type = tcp（必须）local_ip = 被控制主机的本地ip，例如（192.168.123.215）（必须）local_port = Windows默认的远程桌面端口，一般是3389（必须）remote_port = 本地与服务端通信的端口，我是5200（必须）subdomain = router（非必须） 应用frp页面设置后看看padavan的运行日志，如果提示[rdpqiang] start proxy success，说明成功啦~ 接下来我们就可以从 控制主机（以下叫主机A） 远程控制 被控主机（以下叫主机B）。 主机A打开远程桌面，输入 VPS的公网IP:remote_port ，即可访问主机B的桌面啦~ 4、说明一下 每次修改客户端的frp_script后都要应用本页设置。 一个frps只能对应一个frpc 客户端配置时的subdomain可以不填。如果不填，那么访问时只能用VPS的公网ip加端口来访问；如果你有域名，①那么可以在服务端的frps.ini中的subdomain_host填上自己的域名，②在客户端的frpc.ini（padavan里面的frp_script）中的subdomain填任意内容（例如router），③在自己的域名管理网站添加一条解析，例如将router.example.com解析到你VPS的公网ip，然后就可以用域名加端口访问。 更多请访问 frp中文文档 5、目前遇到的问题 提示frpc启动失败, 注意检查端口是否有冲突,程序是否下载完整,10 秒后自动尝试重新启动 解决方法： 1.padavan路由器网络环境下使用WinSCP连接路由器 2.删除/tmp/下的frp文件夹 3.重启路由器就好了 4.如果还是不行，就更新固件。在192.168.123.1路由管理页面，系统管理→控制台，输入wget --no-check-certificate -O- https://opt.cn2qq.com/opt-script/up.sh &gt; /tmp/up.sh &amp;&amp; bash &lt; /tmp/up.sh点刷新，等待自动更新重启就OK了。 5.如果还是不行，可能是padavan系统时间不正确的原因。系统管理→系统时间→ NTP 服务器 1:和NTP 服务器 2:分别填入下列内容 12time1.aliyun.comtime1.apple.com 应用本页设置就可以了~","link":"/2018/10/08/Qat-6Udmg/"},{"title":"DataGrip连接MongoDB使用总结","text":"最近重装了电脑，重新安装了DataGrip，在连接MongoDB遇到一点问题，无法显示完整数据库，找了很久资料，记录一下。 首先打开DataGrip，Alt+Insert，新建Data Source，我直接通过URL添加，点Test Connection测试一下连接是否正常。👩‍💻👩‍💻👩‍💻下面是关键步骤，选择Schemas，勾选All databases或者你需要显示出来的数据库。","link":"/2020/03/16/UZ9aMeLRV/"},{"title":"数据新闻作品","text":"1.从零到世界第一：中国地铁50年 2.川师女生比男生多？37064条数据告诉你不一定","link":"/2020/03/23/hyN07h-Fa/"},{"title":"日区Apple ID绑定国内JCB卡付款","text":"🚗缘起想购买一个App，国区下架了，只有非国区有，淘宝和其他地方倒是很多兑换码，但是看了很多文章说这些兑换码可能来自于黑卡，可能被苹果封号且不能解封，严重的设备也会被封…… 那有没有正规一点的渠道呢？目前大概有这几种主流方案：❌ 1.美区账号，用美区PayPal绑定付款，由于风控非常严格，一旦被封只有提供美国人啥编号，放弃❌2.美区账号，官网购买礼品卡然后绑定到自己账号，最低10刀，太多了，而且余额不好处理，暂不考虑❌3.港区账号，支持绑定AliPay HK，但是大陆居民需要找一个香港手机号注册，且只能找人代充余额，麻烦❌4.港区账号，用香港虚拟信用卡绑定（如拍住赏），大陆居民也只能找别人往里面充钱，太麻烦了✅ 5.日区账号，支持绑定国内JCB信用卡付款，看起来不错，很适合我只需要买一个App，就这个方案了 🚝转区由于本人有一个备用的美区账号，懒得去新注册日区了，appleid.apple.com直接进去换为日区，换了之后网页上要求马上修改“账单寄送地址”，直接搜索“日本人身份生成”，照着填进去就行了，这个假的没关系，不影响付款。然后绑定自己的信用卡，可以在iOS设备上绑，也可以在这绑。 💳支付支付被卡了，大致意思是“无法完成购买，请联系客服”☹️个人推测，这应该是转区导致的风控。 🙋客服我开始以为日本Apple ID得找日本客服，于是在getsupport.apple.com开全局到日本，联系了一个日本客服，由于担心日语翻译不准确，让他们转接到英语服务，一阵沟通后无果，得到答复是他们要下班了，让我打电话找中国客服。 找了下中国400开头的苹果客服号码，全程20多分钟，转接了几次，客服小姐姐声音真甜，一口港台腔。过程中会要求确认你是这个Apple ID的所有者，方法是让你登录appleid.apple.com进去最下面生成一个PIN。最后他们帮我后台操作了一下，让我再试下，由于网络不好，怕他们等太久，就主动说还有问题再联系，他们会向Apple ID邮箱发送这次的案例号，下次联系客服报案例号可以省点时间。 重启了设备，再试了下，还是不行。 再次联系，还是电话联系中国客服，这次直接报案例号，转接几次，通知我处理需要几天，完成后会电话通知我。 🌝成功次日，还没等到客服电话，起床第一件事尝试付款，这次一下就成功了，很顺畅！下午3点客服来电话，但是被手机自动拦截了😂 💰彩蛋充值余额赠送10%的余额，活动截止至2020.4.3 💸总结1️⃣别自作聪明，装外国人，其他区的问题优先联系国区客服解决2️⃣日区价格普遍比其他区贵10%，这好像是日本的消费税？3️⃣最终实际解决问题的客服都是港台腔？","link":"/2020/04/03/MobQbDLNg/"},{"title":"关于","text":"欢迎来到我的小站呀，很高兴遇见你！🤝 🏠 关于本站有时候学会点啥怕忘了就记这 👨‍💻 博主是谁记忆力不太好的一个人 ⛹ 兴趣爱好折腾 📬 联系我呀i@imokey.cn 👫友情链接","link":"/2019/01/25/about/"},{"title":"为博客添加“滑到顶部”按钮","text":"顶部自动隐藏，鼠标悬停切换图片，过渡动画渐变。网上找了很多资料，综合了一下，最终实现了效果。 💷演示效果过渡动画渐变切换图片 “滑到顶端”演示 📙示例代码12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667&lt;!DOCTYPE html&gt;&lt;html lang=&quot;en&quot;&gt;&lt;head&gt; &lt;meta charset=&quot;UTF-8&quot;&gt; &lt;meta name=&quot;viewport&quot; content=&quot;width=device-width, initial-scale=1.0&quot;&gt; &lt;title&gt;演示&lt;/title&gt; &lt;style type=&quot;text/css&quot;&gt; .box { background: url('https://www.imokey.cn/sicnu/img/icon.png') center center no-repeat; background-size: contain; position:fixed; right:10px; bottom:10px; height:40px; width: 40px; -webkit-transition: all .3s ease-in-out; -moz-transition: all .3s ease-in-out; transition: all .3s ease-in-out; } .box:hover { position:fixed; right:10px; bottom:10px; height:40px; width: 40px; background-image: url('https://www.imokey.cn/sicnu/img/totop.png'); } &lt;/style&gt;&lt;/head&gt;&lt;body style=&quot;height:2000px;&quot;&gt;&lt;div id=&quot;box&quot; class=&quot;box&quot;&gt;&lt;/div&gt;&lt;script&gt; window.onload = function(){ document.getElementById(&quot;box&quot;).style.display = &quot;none&quot;; } window.onscroll = function () { if (document.documentElement.scrollTop + document.body.scrollTop &gt; 100) { document.getElementById(&quot;box&quot;).style.display = &quot;block&quot;; } else { document.getElementById(&quot;box&quot;).style.display = &quot;none&quot;; } } var timer = null; box.onclick = function(){ cancelAnimationFrame(timer); var startTime = +new Date(); var b = document.body.scrollTop || document.documentElement.scrollTop; var d = 500; var c = b; timer = requestAnimationFrame(function func(){ var t = d - Math.max(0,startTime - (+new Date()) + d); document.documentElement.scrollTop = document.body.scrollTop = t * (-c) / d + b; timer = requestAnimationFrame(func); if(t == d){ cancelAnimationFrame(timer); } }); }&lt;/script&gt;&lt;/body&gt;&lt;/html&gt; ✅详细阐释1️⃣HTML部分1&lt;div id=&quot;box&quot; class=&quot;box&quot;&gt;&lt;/div&gt; 用一个div标签来放置“滑到顶端”按钮，id用于js定位，class用于css定位 2️⃣CSS部分1234567891011121314151617181920.box { background: url('https://www.imokey.cn/sicnu/img/icon.png') center center no-repeat; background-size: contain; position:fixed; right:10px; bottom:10px; height:40px; width: 40px; -webkit-transition: all .3s ease-in-out; -moz-transition: all .3s ease-in-out; transition: all .3s ease-in-out;}//鼠标未悬停至图片上方的样式.box:hover { position:fixed; right:10px; bottom:10px; height:40px; width: 40px; background-image: url('https://www.imokey.cn/sicnu/img/totop.png');}//鼠标悬停至图片上方的样式 3️⃣ javascript部分这部分主要是为了实现网页初始加载完成后隐藏按钮，或滑到顶部后隐藏，滑到下面出现 1234567891011window.onload = function(){ document.getElementById(&quot;box&quot;).style.display = &quot;none&quot;;}//网页初始加载完成后隐藏按钮window.onscroll = function () { if (document.documentElement.scrollTop + document.body.scrollTop &gt; 100) { document.getElementById(&quot;box&quot;).style.display = &quot;block&quot;; } //滑到下面出现 else { document.getElementById(&quot;box&quot;).style.display = &quot;none&quot;; } //滑到顶部后隐藏} 这部分实现按时间滑到页面顶部，这里设置的是500ms 123456789101112131415161718var timer = null;box.onclick = function(){ cancelAnimationFrame(timer); //获取当前毫秒数 var startTime = +new Date(); //获取当前页面的滚动高度 var b = document.body.scrollTop || document.documentElement.scrollTop; var d = 500;//过渡时间，可自行调整 var c = b; timer = requestAnimationFrame(function func(){ var t = d - Math.max(0,startTime - (+new Date()) + d); document.documentElement.scrollTop = document.body.scrollTop = t * (-c) / d + b; timer = requestAnimationFrame(func); if(t == d){ cancelAnimationFrame(timer); } });}","link":"/2020/03/26/iMDyJgWV9/"},{"title":"Affinity全系半价，一次付费终身授权，90天免费试用","text":"Affinity发布公告，其全平台所有产品半价销售，包括Mac、Windows和iOS三个平台，特别是Mac和Windows平台还可免费使用90天。半价活动持续时间至2020年4月20日，如果你想要购买但不知是否值得购买，可以试用一段时间再决定。 🙋‍♂什么是Affinity？Affinity是英国一家名为Serif 公司的产品，其Affinity Photo对应Adobe Photoshop（以下简称PS），Affinity Designer对应Adobe Illustrator，Affinity Publisher对于Adobe InDesign。虽然说对标，比起Adobe大哥风风雨雨这么多年，Affinity当然有很多地方比不上的地方，但是既然介绍了，Affinity就有它的优势。 💰价格Affinity官网的价格基本一致，都是按照汇率折算的，但是不会按照实时汇率更新，我了解到现在目前最低的价格是澳大利亚38.99澳元，折合人民币160元左右，而中国区价格163元，所以差不多，没必要去买其他区的。要用正版PS，Adobe的PS最便宜的应该是摄影师套餐，中国区一年订阅费用888元人民币。相比Adobe按订阅付费，Affinity是一次性买断制，而且现在价格应该是历史最低价了，非常值得入手。另外购买时会让你填写账号地区，一旦填写不可更改，货币按照该地区货币支付，中国地区不支持PayPal（部分国家支持），仅支持Mastercard和Visa，也不支持银联。如果你只有银联卡，可以试试MicroSoft Store中国区直接购买，不过里面是按照实时汇率折算的，可能会比官网贵一点。 💻界面和使用下面以我自己常用的Affinity Photo简单介绍一下。 👁分辨率我的电脑分辨率比较高但是屏幕只有13寸，PS界面看起来图标和字体非常小，用网上一些方法改了之后可以变大但是字体会模糊，当然是很早之前的PS CS6了，不知道现在有没有适配。但是Affinity暂时没发现这个问题，分辨率方面解决得比较好，但是也有个小问题是左下角的图标显示不完全，也不能拖动，暂时还没找到解决方法。 ✔️支持格式首先亲测，可以肯定的是支持PSD格式文件，并且可再编辑，我截了一张图是支持的导出格式，我想可以导出的格式它也都支持编辑吧👀。 🎲功能Affinity Photo的安装包只有500M，而对应的PS安装包怎么也得G为单位吧，所以粗略得出结论是Affinity Photo没有PS功能全面。但是，对于我这种PS入门级玩家来说，PS大部分功能我是用不到的，或者说不会用🙊，因此Affinity Photo已经非常足够了，平时找个PSD模板小小改动一下、扣个简单图、做个网页头图等等简单操作，对于我来说已经足够了。其实Affinity Photo有些功能体验感甚至比PS还要好，比如抠图。 📝教程众所周知，PS教程铺天盖地，因为使用的人众多（虽然我国使用的大部分都是盗版的🙊）。Affinity Photo官方的教程是英文的，B站有搬运翻译成中文的，第三方教程很少，中文第三方教程就更少了，不过总还是能慢慢找到方法的，毕竟比PS简单很多。相信以后会有越来越多的教程的，万一某天你我从等教程的人变成写教程的人呢🙈 🌓系统资源占用Affinity Photo真的比PS轻便很多，占用系统资源极少，基本不会卡顿，我用的4年前的笔记本运行毫无压力。 📙总结 Adobe Photoshop Affinity Photo 按月/年订阅付费 一次性买断 中国区最低套餐888元/年 中国区价格163元终身 功能全面完善 功能简洁不全面 使用教程丰富 使用教程较少 支持PSD等多种格式 几乎完美兼容PSD等多种文件格式 一个账号最多登入两个设备，但不能同时使用 支持多设备使用（未测试） Affinity Photo我才用了几天时间，很多都没介绍全，不过如果你不是一个深度PS用户，只需要简单的图片编辑功能，那么这款软件是个不错的选择。 Affinity官网","link":"/2020/03/24/pnxNQj07K/"},{"title":"Python+MongoDB实现校园通知聚合推送","text":"🌵需求在学校，有很多通知都是通过网站发布的，比如官网，教务处，图书馆等，如果我想看有没有通知，得去每个网站挨个看，非常不方便。此外，考研期间需要及时了解研招网的通知，要是能有个可个人定制的聚合通知就好了。 🎄分析一般来说，比较古老而通用的解决方案是使用RSS。现今已经有比较优秀成熟的开源项目，可快速制作一个网站的RSS订阅源，比如RSSHub，可惜他们被q了。而且对于能少则少的我来说，不太想多装一个RSS阅读器App。 那就自己动手做一个吧，主要思路是Python定时爬取后存入MongoDB,再全部整理好所有新通知，通过邮件推送到手机。 🌲实现文件结构1234567891011121314│ Check_and_Send_1.1.py│ run_all_py_1.1.py├─jwc_sicnu_edu_cn│ jwc_sicnu_edu_cn_1.1.py├─jy_sicnu_edu_cn│ jy_sicnu_edu_cn_1.1.py├─lib_sicnu_edu_cn│ lib_sicnu_edu_cn_1.1.py├─sicnu_edu_cn│ sicnu_edu_cn_1.1.py├─yz_chsi_com_cn│ yz_chsi_com_cn_1.1.py└─yz_cuc_edu_cn yz_cuc_edu_cn_1.1.py 每个网站py文件大同小异，以域名命文件，想要啥网站可自己加。 run_all_py_1.1.py主要完成运行指定py文件。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263# -*- coding: utf-8 -*-import osimport os.pathimport datetimeimport smtplibfrom email.mime.text import MIMETextfrom email.utils import formataddr# 记录日志def write_info(str): with open ('log.txt','a+') as f: f.write('\\n'+str) f.close()#发送邮件通知def send_mail(copyfrom,title,account,content_html): my_sender='xxxxx@163.com' my_pass = 'abcdefghijk' my_user = account def mail(): ret=True try: html = f&quot;&quot;&quot; {content_html} &quot;&quot;&quot; msg = MIMEText(html, 'html', 'utf-8') msg['From']=formataddr([copyfrom,my_sender]) msg['To']=formataddr([account,my_user]) msg['Subject']= title server=smtplib.SMTP_SSL(&quot;smtp.163.com&quot;, 465) server.login(my_sender, my_pass) server.sendmail(my_sender,[my_user,],msg.as_string()) server.quit() except Exception: ret=False return ret ret=mail() if ret: write_info(f'{datetime.datetime.now():%Y-%m-%d %H:%M:%S} 邮件发送成功至{account}') else: write_info(f'{datetime.datetime.now():%Y-%m-%d %H:%M:%S} 邮件发送至{account}失败')def main(): all_information = [] for i in filename: filepath = f&quot;/root/common_spyder/{i}/{i}_{version}.py&quot; if os.path.isfile(filepath) is True: os.system(f&quot;/root/anaconda3/bin/python {filepath}&quot;) else: all_information.append(i) if len(all_information) is not 0: send_mail(&quot;错误提醒&quot;, &quot;run_all_py.py错误&quot;, 'i@imokey.cn', all_information) else: passif __name__ == '__main__': # 输入文件名 filename = ['jwc_sicnu_edu_cn', 'sicnu_edu_cn', 'lib_sicnu_edu_cn', 'yz_cuc_edu_cn', 'yz_chsi_com_cn'] version = '1.1' main() yz_cuc_edu_cn_1.1.py主要功能是完成通知的爬取和数据存储，其中元素定位使用的是XPath。在此仅举一例，其他网页通知类似，不再赘述。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071# -*- coding: utf-8 -*-import requestsimport pymongoimport timeimport datetimeimport smtplibimport osfrom lxml import etreefrom email.mime.text import MIMETextfrom email.utils import formataddr# 定义日志def write_info(str): pyfile = f'{os.path.basename(__file__)}' with open('log.txt', 'a+') as f: f.write('\\n' + '[' + pyfile + '] ' + str) f.close()# 定义通知信息爬取def requestHTML(index_url): response = requests.get(index_url, headers=headers) response.encoding = charset page = etree.HTML(response.text) title = page.xpath(title_xpath) title_url = page.xpath(title_url_xpath) title_date = page.xpath(title_date_xpath) return title, title_url, title_date# 定义数据库插入def pymongo_insert(): myclient = pymongo.MongoClient(&quot;mongodb://root:abcde123@xxxxx.com:27017/&quot;) mydb = myclient[database] mycol = mydb[collection] title, title_url, title_date = requestHTML(index_url) insert_results = {'success': 0, 'failure': 0} for (t1, t2, t3) in zip(title, title_url, title_date): if is_title_url_prefixion is 1: t2 = t2.replace('..', title_url_prefixion) else: pass added_date = f'{datetime.datetime.now():%Y-%m-%d %H:%M:%S}' mydict = {&quot;title&quot;: t1, &quot;title_url&quot;: t2, &quot;title_date&quot;: t3, &quot;is_new&quot;: 1, &quot;source&quot;: source, &quot;added_date&quot;: added_date} print(mydict) if mycol.find_one({&quot;title&quot;: t1}) is None: # 以标题是否相同作为判断新旧通知标准 result = mycol.insert_one(mydict) insert_results['success'] = insert_results['success'] + 1 else: insert_results['failure'] = insert_results['failure'] + 1 write_info(f'{datetime.datetime.now():%Y-%m-%d %H:%M:%S} 插入成功{insert_results[&quot;success&quot;]}条,{insert_results[&quot;failure&quot;]}条数据已存在')if __name__ == &quot;__main__&quot;: # 填入信息 charset = &quot;gb2312&quot; index_url = &quot;http://yz.cuc.edu.cn/listWYFHY/list_0_1.htm&quot; database = &quot;campus_info_spider&quot; collection = &quot;yz_cuc_edu_cn&quot; is_title_url_prefixion = 1 title_url_prefixion = 'http://yz.cuc.edu.cn' source = &quot;中国传媒大学研招办&quot; title_xpath = '//*[@id=&quot;CONTENT_MAIN&quot;]/table[1]/tr[position()&lt;=last()]/td[1]/a/text()' title_url_xpath = '//*[@id=&quot;CONTENT_MAIN&quot;]/table[1]/tr[position()&lt;=last()]/td[1]/a/@href' title_date_xpath = '//*[@id=&quot;CONTENT_MAIN&quot;]/table[1]/tr[position()&lt;=last()]/td[2]/text()' headers = { &quot;User-Agent&quot;: &quot;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) &quot; &quot;Chrome/72.0.3626.96 Safari/537.36&quot;, } pymongo_insert() Check_and_Send_1.1.py主要完成从数据库读取标记为新通知的数据，然后整理成HTML表格，通过邮箱推送。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118# -*- coding: utf-8 -*-import sysimport pandas as pdimport pymongoimport timeimport datetimeimport smtplibimport osfrom email.mime.text import MIMETextfrom email.utils import formataddr# 定义日志def write_info(str): pyfile = f'{os.path.basename(__file__)}' with open('log.txt', 'a+') as f: f.write('\\n' + '[' + pyfile + '] ' + str) f.close()# 定义发送邮件def send_mail(copyfrom,title,account,all_content_html): my_sender='xxxxx@163.com' my_pass = 'abcdefghijk' my_user = account def mail(): ret=True try: str = '&lt;br&gt;' combined_content_html = str.join(all_content_html) html = f&quot;&quot;&quot;{combined_content_html}&quot;&quot;&quot; msg = MIMEText(html, 'html', 'utf-8') msg['From']=formataddr([copyfrom,my_sender]) msg['To']=formataddr([account,my_user]) msg['Subject']= title server=smtplib.SMTP_SSL(&quot;smtp.163.com&quot;, 465) server.login(my_sender, my_pass) server.sendmail(my_sender,[my_user,],msg.as_string()) server.quit() except Exception: ret=False return ret ret=mail() if ret: write_info(f'{datetime.datetime.now():%Y-%m-%d %H:%M:%S} 邮件发送成功至{account}') else: write_info(f'{datetime.datetime.now():%Y-%m-%d %H:%M:%S} 邮件发送至{account}失败')# 定义数据库查询遍历，选出所有新通知def pymongo_traverse(increment): myclient = pymongo.MongoClient(&quot;mongodb://root:abcde123@xxxxx.com:27017/&quot;) mydb = myclient[&quot;campus_info_spider&quot;] coll_names = mydb.list_collection_names(session=None) for c in coll_names: mycol = mydb[c] all_new = mycol.find({&quot;is_new&quot;: 1}) for x in all_new: print(x) increment.append(x) pymongo_update(c) convertToHtml(increment) increment = []# 定义数据库更新，用于将数据库中新通知标记去掉def pymongo_update(c): myclient = pymongo.MongoClient(&quot;mongodb://root:abcde123@xxxxx.com:27017/&quot;) mydb = myclient[&quot;campus_info_spider&quot;] mycol = mydb[c] status = mycol.update_many({&quot;is_new&quot;: 1}, {'$set': {&quot;is_new&quot;: 0}}) write_info(f'{datetime.datetime.now():%Y-%m-%d %H:%M:%S} 在{c}中共修改{status.modified_count}条')# 定义将获取的新通知数据转换为HTML表格def convertToHtml(increment): if len(increment) !=0: result = [[], []] for x in increment: title_url = x['title_url'] title = x['title'] result[1].append(f'&lt;a href=&quot;{title_url}&quot;&gt;{title}&lt;/a&gt;') count = len(increment) for i in range(1,count+1): result[0].append(i) d = {} index = 0 source = increment[0]['source'] title = ['编号', source] for t in title: d[t] = result[index] index = index+1 df = pd.DataFrame(d) df = df[title] content_html = df.to_html(escape=False, index=False, col_space=25, justify=&quot;center&quot;) all_content_html.append(content_html) else: pass# 定义获取数据库中存储的用户邮箱def get_mail_accounts(mail_accounts): myclient = pymongo.MongoClient(&quot;mongodb://root:abcde123@xxxxx.com:27017/&quot;) mydb = myclient[&quot;accounts&quot;] mycol = mydb[&quot;mail_accounts&quot;] all_new = mycol.find({&quot;status&quot;: 1}) for a in all_new: mail_accounts.append(a['accounts'])if __name__ == '__main__': copyfrom = &quot;校园通知聚合&quot; title = &quot;新通知提醒&quot; increment = [] all_content_html = [] mail_accounts = [] pymongo_traverse(increment) get_mail_accounts(mail_accounts) if len(all_content_html)!=0 and len(mail_accounts)!=0: for account in mail_accounts: send_mail(copyfrom, title, account, all_content_html) else: pass 🌱运行放在阿里云上，用crontab每天9-21点，每隔3小时定时执行。也可以按需改得更频繁，越频繁爬取越容易被ban掉IP。 1crontab -e 1255 8,11,14,17,20 * * * cd /root/common_spyder &amp;&amp; /root/anaconda3/bin/python run_all_py_1.1.py0 9,12,15,18,21 * * * cd /root/common_spyder &amp;&amp; /root/anaconda3/bin/python Check_and_Send_1.1.py 🌴效果","link":"/2020/03/15/mOUjz58q7/"},{"title":"IDM下载报错：安装文件时出现错误","text":"最近在用IDM下载有关资料时，到100%时会提示安装文件时出现错误，网上找了中文解决方案没找到，用英文搜索到有关一个老哥的视频，记录一下解决方法。报错如下⬇️可能是我之前手动设置了代理的原因，需要调整到与系统代理一致才解决了错误。IDM进选项➡️代理服务器选中使用系统设置然后重启IDM应该就可以了。🙊另我是买的正版激活码，软件也是在官网下的，所以应该不是盗版的问题。","link":"/2020/03/18/sCRfunyPP/"},{"title":"Win10开启文件共享，SMB端口转发","text":"📂需求最近需要在校园网内共享win10上的一个文件夹，但是2017年因为勒索病毒，不少学校网络管理员把445端口给封了，导致校园网内不能访问Win10共享出来的文件夹。网上这方面解决办法挺少的，故想记录一下通过转发smb445端口解决该需求的过程。 一、服务端共享文件夹首先，选定要共享的文件夹，右键点击“属性”，标签选择“共享”，选择你的Windows账户，然后共享。 二、服务端端口转发win10默认的共享端口是445，由于历史原因，某些网络管理把445端口封禁了，因此需要将计算机（服务端）某个端口（本文选择4455）转发给445端口。大致的原理是 客户端访问服务端IP:4455 -&gt; 服务端将4455映射到445 -&gt; 实现间接访问服务端445。 首先管理员权限下打开cmd，输入命令 1netsh interface portproxy add v4tov4 listenaddress=0.0.0.0 listenport=[对外端口] connectaddress=127.0.0.1 connectport=445 查看是否设置成功 1netsh interface portproxy show all 三、服务端防火墙设置打开控制面板，系统和安全-Windows Defender 防火墙-高级设置-入站规则-新建规则选择端口选择TCP，特定本地端口填上面第一条命令listenport的端口号名称可自行取一个显然的名称，点击完成即可。 四、客户端连接Mac访达-右键-连接服务器 1smb://[服务端内网IP]:[listenport端口号] 可能需要输入window的账号和密码。 iOS可使用自带的“文件”应用，也可下载第三方的应用，如nplayer、infuse等。 Windows貌似暂不支持连接转发后的端口。 参考知乎：Windows 10 下如何修改 smb 连接的默认端口(445)？sunse：Windows使用netsh完成端口转发","link":"/2021/07/28/v0Mq2io5w/"},{"title":"Nginx通过指定url访问不同路径文件","text":"🍊场景已经有一个静态项目运行，url为www.example.com，存放于/data/www。现需要将存放于/data/xxxxx的另一个静态项目运行，且指定url为www.example.com/xxxxx/index.html。 🍅实现方案一:root在nginx配置文件中，server中的末尾加入 1234567server {#此处省略若干行 location /xxxxx/ { root /data;#注意此处差异 index index.html; }} 此时访问www.example.com/xxxxx/index.html，对应访问服务器上的文件/data/xxxxx 方案二:alias在nginx配置文件中，server中的末尾加入 1234567server {#此处省略若干行 location /xxxxx/ { alias /data/xxxxx/;#注意此处差异，这里结尾必须加`/` index index.html; }} 此时访问www.example.com/xxxxx/index.html，对应访问服务器上的文件/data/xxxxx 🌽区别它们对路径的解析方式不同，alias会把指定路径当作文件路径，而root会把指定路径拼接到文件路径后，再进行访问。 参考lkning","link":"/2020/05/07/QqS5PUfX2/"}],"tags":[{"name":"Python","slug":"Python","link":"/tags/Python/"},{"name":"汇总","slug":"汇总","link":"/tags/%E6%B1%87%E6%80%BB/"},{"name":"selenium","slug":"selenium","link":"/tags/selenium/"},{"name":"DoH&#x2F;DoT","slug":"DoH-DoT","link":"/tags/DoH-DoT/"},{"name":"Nginx","slug":"Nginx","link":"/tags/Nginx/"},{"name":"ssl证书","slug":"ssl证书","link":"/tags/ssl%E8%AF%81%E4%B9%A6/"},{"name":"CDN","slug":"CDN","link":"/tags/CDN/"},{"name":"TextBlob","slug":"TextBlob","link":"/tags/TextBlob/"},{"name":"NLP","slug":"NLP","link":"/tags/NLP/"},{"name":"内网穿透","slug":"内网穿透","link":"/tags/%E5%86%85%E7%BD%91%E7%A9%BF%E9%80%8F/"},{"name":"frp","slug":"frp","link":"/tags/frp/"},{"name":"Padavan","slug":"Padavan","link":"/tags/Padavan/"},{"name":"老毛子","slug":"老毛子","link":"/tags/%E8%80%81%E6%AF%9B%E5%AD%90/"},{"name":"MongoDB","slug":"MongoDB","link":"/tags/MongoDB/"},{"name":"DataGrip","slug":"DataGrip","link":"/tags/DataGrip/"},{"name":"数据新闻","slug":"数据新闻","link":"/tags/%E6%95%B0%E6%8D%AE%E6%96%B0%E9%97%BB/"},{"name":"Data News","slug":"Data-News","link":"/tags/Data-News/"},{"name":"折腾日记","slug":"折腾日记","link":"/tags/%E6%8A%98%E8%85%BE%E6%97%A5%E8%AE%B0/"},{"name":"Apple ID","slug":"Apple-ID","link":"/tags/Apple-ID/"},{"name":"JavaScript","slug":"JavaScript","link":"/tags/JavaScript/"},{"name":"CSS","slug":"CSS","link":"/tags/CSS/"},{"name":"HTML","slug":"HTML","link":"/tags/HTML/"},{"name":"Affinity","slug":"Affinity","link":"/tags/Affinity/"},{"name":"IDM","slug":"IDM","link":"/tags/IDM/"},{"name":"文件共享","slug":"文件共享","link":"/tags/%E6%96%87%E4%BB%B6%E5%85%B1%E4%BA%AB/"},{"name":"SMB","slug":"SMB","link":"/tags/SMB/"}],"categories":[]}